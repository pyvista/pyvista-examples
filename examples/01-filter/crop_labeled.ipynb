{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crop Labeled ImageData {#crop_labeled_example}\n======================\n\nUse `~pyvista.ImageDataFilters.crop`{.interpreted-text role=\"meth\"} to\ncrop labeled data such as segmented medical images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport pyvista as pv\nfrom pyvista import examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a dataset with a CT image and corresponding segmentation labels.\nHere we load\n`~pyvista.examples.downloads.download_whole_body_ct_male`{.interpreted-text\nrole=\"func\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = examples.download_whole_body_ct_male()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the `~pyvista.ImageData`{.interpreted-text role=\"class\"} for the CT\ndata and one of the segmentation masks. For this example we choose a\nmask of the skull.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ct = dataset['ct']\nskull = dataset['segmentations']['skull']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crop the CT image using the segmentation mask. Use `padding` to include\nadditional data points around the masked region.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropped_ct = ct.crop(mask=skull, padding=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `~pyvista.ImageDataFilters.points_to_cells`{.interpreted-text\nrole=\"meth\"} to plot the cropped image as\n`~pyvista.CellType.VOXEL`{.interpreted-text role=\"attr\"} cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cpos = [(687.5, 763.6, 471.3), (231.8, 296.3, 677.0), (0.107, 0.311, 0.944)]\n\ncropped_ct_voxels = cropped_ct.points_to_cells()\ncropped_ct_voxels.plot(volume=True, cpos=cpos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Include a surface contour of the mask with the plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "skull_surface = skull.contour_labels()\n\npl = pv.Plotter()\npl.add_mesh(skull_surface, color='white')\npl.add_volume(cropped_ct_voxels)\npl.camera_position = cpos\npl.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After cropping, the CT image\\'s dimensions are smaller than the mask\\'s.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropped_ct.dimensions == skull.dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To keep dimension the same, either\n\n1.  crop the mask itself; the meshes will have smaller dimensions\n    relative to the input\n2.  pad the CT image as part of the initial crop; the meshes will have\n    the same dimensions as the input\n\nTo crop the mask itself, you can perform a similar crop as before using\n`mask=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropped_skull = skull.crop(mask=True, padding=10)\ncropped_skull.dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, computationally it is more efficient to crop using `extent`\ndirectly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropped_skull = skull.crop(extent=cropped_ct.extent)\ncropped_skull.dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, use `keep_dimensions` and `fill_value` when initially\ncropping the image so that the output dimensions match the input. A\nvalue of `-1000` is used, which may represent air in the scan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropped_ct = ct.crop(mask=skull, keep_dimensions=True, fill_value=-1000)\ncropped_ct.dimensions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}